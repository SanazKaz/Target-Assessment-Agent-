{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio  # Add this import\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from APIs.combinedapi import PubMedProcessor\n",
    "%autoawait asyncio\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "openai_client = OpenAI(api_key=\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "llm = ChatOpenAI(api_key=\"OPENAI_API_KEY\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_prompt = \"\"\"# IMPORTANT:\n",
    "Try to answer this question/instruction with step-by-step thoughts and make the answer more structural.\n",
    "Use `\\n\\n` to split the answer into several paragraphs.\n",
    "Just respond to the instruction directly. DO NOT add additional explanations or introducement in the answer unless you are asked to.\n",
    "'''Develop a scientific rationale for the following:\n",
    "                             \n",
    "                             You are a AI assistant with a background in drug discovery.\n",
    "\n",
    "    Given target: Gamma secretase\n",
    "    Given disease: Alzheimer's disease\n",
    "    Given mode of action: Gamma secretase is a multi-subunit protease complex that cleaves type I transmembrane proteins, including the amyloid precursor protein (APP) leading to the generation of amyloid-beta (Aβ) peptides.\n",
    "\n",
    "    Context:\n",
    "     Aβ is a family of secreted peptides generated from the sequential cleavages of the type 1 membrane protein APP by beta-secretase (BACE) and gamma-secretase (GSEC), respectively. \n",
    "      BACE cleaves APP in the luminal domain, releasing the N-terminal soluble APPβ domain and leaving the C-terminal fragment, APP-CTF, which remains in the membrane. \n",
    "      Subsequently, the APP-CTF is recruited to GSEC, a complex comprising four subunits, including PS, which harbors the active site. GSEC first cuts APP-CTF at the epsilon-cleavage site located close to the inner leaflet of the membrane. \n",
    "      This cleavage event produces either Aβ48 or Aβ49 and the APP intracellular domain (AICD). The membrane-retained Aβ48 or Aβ49 is then further processed by GSEC in a continuous cascade of proteolytical events at every third of fourth amino acid, where the N-terminal product of each reaction becomes the substrate for the next GSEC cleavage event.\n",
    "       Accordingly, GSEC processes APP-CTF along two main product lines, Aβ49 → 46 → 43 → 40 → 37… and Aβ48 → 45 → 42 → 38…, respectively (Takami et al., 2009; Matsumura et al., 2014; Olsson et al., 2014). During this processing cascade, Aβ43 and shorter Aβ peptides stochastically escape further processing by GSEC and are released into the extracellular space. \n",
    "      As a result, Aβ peptides varying from 30 to 43 amino acids in length are secreted into the extracellular space. Among all secreted Aβ, Aβ40 is the most abundant in human CSF, followed by Aβ38, Aβ42, and Aβ37 (Liu et al., 2022). In cognitively normal individuals, Aβ42 and Aβ43 represent a smaller portion of the total secreted Aβ (Liu et al., 2022).\n",
    "         These longer forms of Aβ seed the formation of Aβ-amyloid aggregates, a key step in the formation of amyloid plaques (Veugelen et al., 2016), as illustrated in Figure 1. Aβ42, which is produced in higher amounts than Aβ43, is the most abundant Aβ in amyloid plaques (Welander et al., 2009).\n",
    "\n",
    "\n",
    "    Task 1: Develop a scientific rationale for Gamma secretase in Alzheimer's disease.\n",
    "\n",
    "    Highlight the working hypothesis for the clinical target rationale and human biology evidence by minimum 2000 words.\n",
    "\n",
    "    Describe as much as possible the evidence in humans or in human tissue that link the target, target space or approach to the pathogenesis of interest.\n",
    "    If known, also describe here the wanted mode of action with regards to desired clinical outcome.\n",
    "    Please avoid including only pre-clinical data in this section.\n",
    "\n",
    "    Use the following structure and provide a detailed description for each point:\n",
    "    - Working hypothesis:\n",
    "    - Create a detailed description of the following idea: Develop an inhibitor of the neurokinin 3 receptor (NK3R) GPCR for the treatment of vasomotor symptoms due to menopause.\n",
    "    - Is there are significant unmet medical need?\n",
    "    - Is it suitable for combination therapy?\n",
    "    - Which predictive biomarkers exist for the target related to the disease?\n",
    "        - Provide a detailed description of existing clinical relevant biomarkers.\n",
    "\n",
    "    - Clinical target rationale:\n",
    "    - How relevant is the target location to the disease biology?\n",
    "    - How it the target expression altered in human disease?\n",
    "    - How is the target involved in the physiological process relevant to the disease?\n",
    "    - Which phenotypes and genotypes were identified for the target?\n",
    "    - How is the genetic link between the target and the disease?\n",
    "    - Describe the evidence provided in clinics or by tools acting on the pathway where the target is involved.\n",
    "    - Which kind of target modulation is required to treat the disease?\n",
    "\n",
    "    - Challenges for the drug discovery program related to the target.\n",
    "    - Check the following idea for details on small molecule compounds: Develop an inhibitor of the neurokinin 3 receptor (NK3R) GPCR for the treatment of vasomotor symptoms due to menopause..\n",
    "    - Is a 'information driven approach' (IDA) strategy based on available small molecules possible?\n",
    "        - Which small molecular modulators of the target known?\n",
    "        - Which inhibitors, antagonists, agonists, negative allosteric modulators (NAM), positive allosteric modulators (PAM) are required for target modulation in the given disease? \n",
    "    - Which patients would respond the therapy?\n",
    "    - Is the proposed mode of action on the target desirable and commercially viable in a clinical setting?\n",
    "    - What are advantages and disadvantages of different therapeutic modalities (antibodies, small molecules, antisense oligonucleotides, PROTACs, molecular glue, peptide macrocycles, and so on) for tackling the target?\n",
    "\n",
    "    - Alternative indications:\n",
    "    - Describe alternative indication for modulators of the target and explain why.\"\"\"\n",
    "\n",
    "\n",
    "scientific_rationale_system_prompt = \"\"\"You are 'scientific rationale', an expert in target discovery and assessment at a pharmaceutical company, you get commission when you assess and discovery a new target. \n",
    "                        You provide scientific rationales to support the selection of drug targets for a specific disease.\n",
    "                        You are meticulous in your analysis and provide evidence-based assessments to guide drug discovery efforts.\n",
    "                        Your role is to:\n",
    "                        1. Your primary role is to develop comprehensive scientific rationales for given targets in specified diseases using available literature. \"\"\"\n",
    "\n",
    "\n",
    "refine_prompt ='''\n",
    "Referencing the answers provided by all agents, synthesize a more detailed and comprehensive response by integrating all relevant details from these answers. Ensure logical coherence and provide ONLY THE MERGED ANSWER AS THE OUTPUT, omitting any discussion of the comparison process or analytical thoughts.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any\n",
    "import openai\n",
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "async def pubmed_paperqa(query: str) -> Dict[str, Any]:\n",
    "    \"\"\" Searches PubmedCentral for papers using a query\n",
    "    and returns the most relevant chunks using paperQA\"\"\"\n",
    "    \n",
    "    max_results: int = 10\n",
    "    pubmed_query = query\n",
    "    doc_query = query\n",
    "    email = \"sanazkazemi@hotmail.com\"\n",
    "    print(f\"pubmed_paperqa called with query: {query}, max_results: {max_results}\")\n",
    "    \n",
    "    pubmed_instance = PubMedProcessor(email)\n",
    "    results_dict = await pubmed_instance.full_process(pubmed_query, doc_query, max_results)\n",
    "    \n",
    "    return json.dumps(results_dict, indent=4)\n",
    "\n",
    "# To run this in a Jupyter notebook cell:\n",
    "# query = \"Alzheimer's disease and gamma secretase\"\n",
    "# results = await pubmed_paperqa(query)\n",
    "# print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pick_best_query(queries: list, question: str) -> str:\n",
    "    \"\"\"picks the best query from the list of queries\"\"\"\n",
    "\n",
    "    gpt_prompt =\"\"\"\n",
    "    for the given question, pick the best query \n",
    "    from the list of queries that you think is most relevant to the question.\n",
    "    ## IMPORTANT:\n",
    "    Just return the best query. Do not add any additional information.\n",
    "    \"\"\"\n",
    "\n",
    "    best_query = openai.chat.completions.create(\n",
    "\n",
    "     model = \"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"you are a scientific researcher, you are tasked with finding the best query to search for scientific papers on PubMed.\"            \n",
    "        },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"##Instruction:{gpt_prompt}\\n\\n###Question: {question}\\n\\n##Queries: {[queries]}\\n\\n\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.7 # here you can adjust the temperature to get more or less creative search terms\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    return best_query\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_query(question, answer, num_queries) -> str:\n",
    "\n",
    "    \"\"\"Generates queries to search for in Pubmed based on the question\"\"\"    \n",
    "    query_prompt = \"\"\" You are a scientific researcher, \n",
    "                        you are tasked with finding the best query to search \n",
    "                        for scientific papers on PubMed.\n",
    "                                                    \n",
    "                            I want to verify the content correctness of the given question, especially the last sentences.\n",
    "                            Please summarize the content with the corresponding question.\n",
    "                            This summarization will be used as a query to search with Bing search engine.\n",
    "                            The query should be short but need to be specific to promise Bing can find related knowledge or pages.\n",
    "                            You can also use search syntax to make the query short and clear enough for the search engine to find relevant language data.\n",
    "                            Try to make the query as relevant as possible to the last few sentences in the content.\n",
    "                            **IMPORTANT**\n",
    "                            Just output the query directly. DO NOT add additional explanations or introducement in the answer unless you are asked to.\n",
    "\n",
    "                        The following worked very well for me in the past in terms of generating the highest number of results use it as a guide:\n",
    "                        ###Example:\n",
    "                        \"{Target}\" AND \"{Disease}\" AND (\"{relevant_keyword}\" OR \"{relevant_keyword_1} Or \"{relevant_keyword_n}\")\" and so on.\n",
    "                        ##IMPORTANT:\n",
    "                        Just provide the query. Do not add any additional information.\n",
    "                        DO NOT copy the given example\"\"\"\n",
    "    \n",
    "\n",
    "    queries = []\n",
    "\n",
    "    for i in range(num_queries):\n",
    "        try:\n",
    "            query = openai.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"##Question: {question}\\n\\n##Content: {answer}\\n\\n##Instruction: {query_prompt}\"\n",
    "                    }\n",
    "                ],\n",
    "                temperature=1\n",
    "            ).choices[0].message.content\n",
    "            print(f\"query {i}: {query}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"error {e}\")\n",
    "        queries.append(query)\n",
    "\n",
    "    best_query = pick_best_query(queries, question)\n",
    "    print(f\"best query: {best_query}\")\n",
    "\n",
    "    return best_query\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def main(question: str, answer, num_queries: int):\n",
    "    \"\"\"Main function to get the best query for the question\"\"\"\n",
    "    \n",
    "    \n",
    "    search_query = get_query(question, answer, num_queries)\n",
    "    \n",
    "    # Remove only the outermost single quotes if they exist otherwise doesnt work - not elegant but works\n",
    "    if search_query.startswith(\"'\") and search_query.endswith(\"'\"):\n",
    "        cleaned_query = search_query[1:-1]\n",
    "    else:\n",
    "        cleaned_query = search_query\n",
    "    \n",
    "    # Replace escaped single quotes with regular single quotes\n",
    "    cleaned_query = cleaned_query.replace(\"\\\\'\", \"'\")\n",
    "    \n",
    "    print(f\"Cleaned search query: {cleaned_query}\")\n",
    "    \n",
    "    results = await pubmed_paperqa(cleaned_query)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query 0: \"Gamma secretase\" AND \"Alzheimer's disease\" AND (\"amyloid-beta production\" OR \"neurodegenerative diseases\" OR \"protein aggregation\")\n",
      "query 1: \"Gamma secretase\" AND \"Alzheimer's disease\" AND (\"Aβ42\" OR \"Aβ43\" OR \"amyloid plaques\" OR \"GSEC inhibitors\")\n",
      "query 2: \"Gamma secretase\" AND \"Alzheimer's disease\" AND (\"protein aggregation\" OR \"frontotemporal dementia\" OR \"Parkinson's disease\")\n",
      "query 3: \"Gamma secretase\" AND \"Alzheimer's disease\" AND (\"predictive biomarkers\" OR \"clinical target rationale\" OR \"target modulation\")\n",
      "query 4: \"Gamma secretase\" AND \"Alzheimer's disease\" AND (\"neurodegenerative diseases\" OR \"protein aggregation\" OR \"Parkinson's disease\" OR \"frontotemporal dementia\")\n",
      "best query: '\"Gamma secretase\" AND \"Alzheimer\\'s disease\" AND (\"Aβ42\" OR \"Aβ43\" OR \"amyloid plaques\" OR \"GSEC inhibitors\")'\n",
      "Cleaned search query: \"Gamma secretase\" AND \"Alzheimer's disease\" AND (\"Aβ42\" OR \"Aβ43\" OR \"amyloid plaques\" OR \"GSEC inhibitors\")\n",
      "pubmed_paperqa called with query: \"Gamma secretase\" AND \"Alzheimer's disease\" AND (\"Aβ42\" OR \"Aβ43\" OR \"amyloid plaques\" OR \"GSEC inhibitors\"), max_results: 10\n",
      "{\n",
      "    \"summary: The study investigates the role of amyloid \\u03b2 (A\\u03b2) peptides, specifically A\\u03b242, in Alzheimer\\u2019s disease (AD), proposing that elevated A\\u03b242 inhibits \\u03b3-secretase activity, thereby impairing downstream signaling. A\\u03b242 treatment leads to the accumulation of unprocessed substrates like C-terminal fragments (CTFs) of amyloid precursor protein (APP) in neurons, indicating disrupted \\u03b3-secretase function. This inhibition contributes to neurodegeneration evidenced by \\u201cp75-dependent neuronal death.\\u201d The work emphasizes a novel mechanism linking A\\u03b242 levels to \\u03b3-secretase inhibition, challenging established views of amyloid toxicity in AD.\\n\\n9\": {\n",
      "        \"original_text\": \"Title: Alzheimer\\u2019s disease linked A\\u03b242 exerts product feedback inhibition on \\u03b3-secretase impairing downstream cell signaling\\n\\nAuthors: Zoltowska Katarzyna Marta, Das Utpal, Lismont Sam, Enzlein Thomas, Maesako Masato, Houser Mei CQ, Franco Mar\\u00eda Luisa, \\u00d6zcan Burcu, Moreira Diana Gomes, Karachentsev Dmitry, Becker Ann, Hopf Carsten, Vilar Mar\\u00e7al, Berezovska Oksana, Mobley William, Ch\\u00e1vez-Guti\\u00e9rrez Luc\\u00eda\\n\\nJournal: bioRxiv\\nYear: 2024\\nPMC ID: 10418207\\nDOI: 10.1101/2023.08.02.551596\\nCitation Count: 0\\n\\nAbstract:\\nAmyloid \\u03b2 (A\\u03b2) peptides accumulating in the brain are proposed to trigger Alzheimer\\u2019s disease (AD). However, molecular cascades underlying their toxicity are poorly defined. Here, we explored a novel hypothesis for A\\u03b242 toxicity that arises from its proven affinity for \\u03b3-secretases. We hypothesized that the reported increases in A\\u03b242, particularly in the endolysosomal compartment, promote the establishment of a product feedback inhibitory mechanism on \\u03b3-secretases, and thereby impair downstream signaling events. We show that human A\\u03b242 peptides, but neither murine A\\u03b242 nor human A\\u03b217\\u201342 (p3), inhibit \\u03b3-secretases and trigger accumulation of unprocessed substrates in neurons, including C-terminal fragments (CTFs) of APP, p75 and pan-cadherin. Moreover, A\\u03b242 treatment dysregulated cellular -homeostasis, as shown by the induction of p75-dependent neuronal death in two distinct cellular systems. Our findings raise the possibility that pathological elevations in A\\u03b242 contribute to cellular toxicity via the \\u03b3-secretase inhibition, and provide a novel conceptual framework to address A\\u03b2 toxicity in the context of \\u03b3-secretase-dependent homeostatic signaling.\\n\\nFull Text:\\n\\u0393-secretases are ubiquitously expressed intramembrane proteases best known for their pathogenic roles in Alzheimer\\u2019s disease (AD) (1). Aberrant processing of the amyloid precursor protein (APP) by \\u03b3-secretases leads to the production of longer, aggregation-prone amyloid \\u03b2 (A\\u03b2) peptides that contribute to neurodegeneration (2). In addition, \\u03b3-secretases process many other membrane proteins, including NOTCH, ERB-B2 receptor tyrosine kinase 4 (ERBB4), N-cadherin (NCAD) and p75 neurotrophin receptor (p75-NTR) (3, 4). The processing of multiple substrates links their activity to a broad range of downstream signaling pathways (5, 6), including those critical for neuronal function. It is noteworthy that treatment with \\u03b3-secretase inhibitors caused cognitive worsening in AD patients (7), while full genetic inhibition of these enzymes in the adult mouse brain led to neurodegenerative phenotypes (8\\u201312). The underlying mechanisms by which the deficits in \\u03b3-secretase activity impair neuronal function are yet to be defined. \\u0393-secretase activity is exerted by a family of highly homologous multimeric proteases composed of presenilin (PSEN1 or PSEN2), nicastrin (NCSTN), anterior pharynx defective 1 (APH1A or B) and presenilin enhancer 2 (PEN2) subunits. The proteolytic activities of these complexes are promoted by the low pH of the endosomal and lysosomal compartments, wherein the amyloidogenic processing\",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Zoltowska2024a chunk 1\",\n",
      "            \"full_citation\": \"Zoltowska, Katarzyna Marta, et al. \\\"Alzheimer\\u2019s Disease Linked A\\u03b242 Exerts Product Feedback Inhibition on \\u03b3-Secretase Impairing Downstream Cell Signaling.\\\" *bioRxiv*, 2024, doi:10.1101/2023.08.02.551596. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 9\n",
      "    },\n",
      "    \"summary: The excerpt suggests that increased levels of A\\u03b242 in endosomes lead to feedback inhibition of \\u03b3-secretase, contributing to Alzheimer's disease (AD) pathogenesis. It posits that the accumulation of A\\u03b242 can cause \\\"\\u03b3-secretase loss-of-function phenotypes,\\\" linking elevated A\\u03b242 levels with inhibited \\u03b3-secretase activity, thus affecting downstream cell signaling. Additionally, it notes that \\\"the isolation of the \\u03b3-secretase releases A\\u03b242,\\\" which may restore normal wild-type activity, providing a mechanism for understanding the relationship between A\\u03b242 and neurodegeneration in AD.\\n\\nScore: 9\": {\n",
      "        \"original_text\": \", we argue that the deposition of A\\u03b242 in plaques may be preceded by a critical increase in the levels of A\\u03b2 present in endosomes and the cyclical inhibition of \\u03b3-secretase activity that we propose. Under this view, reductions in \\u03b3-secretase activity may be a (transient) downstream consequence of increases in A\\u03b2 due to failed clearance, as represented by plaque deposition, contributing to AD pathogenesis. The A\\u03b2-mediated inhibition of \\u03b3-secretase may also help to explain the intriguing accumulation of APP-CTFs in the heterozygous FAD brain (Pera et al., 2013). In this regard, the direct quantification of \\u03b3-secretase activity in detergent-resistant fractions prepared from post-mortem brain samples of healthy controls and FAD-linked mutation carriers revealed similar overall \\u03b3-secretase activity levels, indicating that the wild-type (PSEN1 and PSEN2) \\u03b3-secretase complexes rescue any potential mutation-driven deficits in the processing of APP (Szaruga et al., 2015). Yet APP-CTFs have been reported to accumulate in the FAD brain (Ferrer-Ravent\\u00f3s, 2023; Pera et al., 2013) and the accumulation of APP-CTFs appears to correlate with A\\u03b2 levels at the synapse. The inhibition of \\u03b3-secretase by A\\u03b242 could resolve the apparent conflict. Indeed, our data could reconcile these two seemingly exclusive hypotheses on the effects of FAD mutations in PSEN1 on the development of AD by noting that: (1) there is a mutation-driven enhanced generation of A\\u03b242 within the endolysosomal network; (2) that through both endosomal production and endocytosis A\\u03b242 increases to a level within the endolysosomal network sufficient to inhibit the \\u03b3-secretase complex; and (3) that in the case of FAD mutations the isolation of the \\u03b3-secretase releases A\\u03b242, thus restoring wild-type enzyme activity (Veugelen et al., 2016; Shen and Kelleher, 2007). Thus, increased levels of endolysosomal A\\u03b242 with concurrent inhibition of \\u03b3-secretase may be responsible, at least in part, for the apparent \\u03b3-secretase loss-of-function phenotypes. Collectively, our data raise the intriguing possibility that increases in A\\u03b242 in the AD brain, and in particular in the endolysosomal compartment, facilitate the establishment of an A\\u03b2-driven inhibitory mechanism that contributes to neurotoxicity by impairing critical \\u03b3-secretase signaling functions. By mechanistically connecting elevated A\\u03b242 levels with the accumulation of multiple \\u03b3-secretase substrates, our observations integrate disparate views as to which pathways lead to neurodegeneration and offer a novel conceptual framework for investigating the molecular and cellular bases of AD pathogenesis. A\\u03b2 peptides were purchased from rPeptide, resuspended in DMSO at 500 \\u03bcM, aliquoted into single use 10 \\u03bcl aliquots and stored at \\u201380 \\u00b0C. For A\\u03b242 the following lots were used: 4261242T, 06021342T and 02092242T. \\u0393-secretase inhibitors (Inhibitor X (InhX, L-685,458), DAPT and compound E (CE)) were purchased from Bioconnect, Sigma-Aldrich and Millipore, respectively. TrkA inhibitor K252\\u03b1, cycloheximide and Bafilomycin A1 were purchased from Sigma Aldrich. The following antibodies were used: mouse anti-FLAG M2 (Sigma-Aldrich, F3165), rabbit anti-ADAM10 antibody (EPR5622, Abcam, ab124695), rabbit anti-APP (gift from Prof. Wim Annaert (B63)), rabbit anti-APP (Y188, Abcam, ab32136), mouse anti-APP (22\",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Zoltowska2024 chunk 24\",\n",
      "            \"full_citation\": \"Zoltowska, Katarzyna Marta, et al. \\\"Alzheimer\\u2019s Disease Linked A\\u03b242 Exerts Product Feedback Inhibition on \\u03b3-Secretase Impairing Downstream Cell Signaling.\\\" *eLife*, vol. 13, 2024, doi:10.7554/eLife.90690. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 9\n",
      "    },\n",
      "    \"summary: A\\u03b242 inhibits the \\u03b3-secretase enzyme family, reducing the production of the signaling molecule AICD across various \\u03b3-secretase complexes. In quantitative western blotting, 3 \\u03bcM A\\u03b242 markedly inhibited total AICD production. A\\u03b242 does not serve as a substrate for \\u03b3-secretase under tested conditions, contrasting with A\\u03b243, which is processed into A\\u03b240. A\\u03b242's inhibition is reversible, forming non-productive enzyme-substrate complexes. This suggests that A\\u03b242 interferes with \\u03b3-secretase activity in Alzheimer's disease by binding competitively, thereby impacting amyloid peptide processing. \\n\\n9\": {\n",
      "        \"original_text\": \"99) (Figure 1C), indicating that A\\u03b242 inhibits both \\u03b3-secretase product lines. Next, we tested whether human A\\u03b242 exerted inhibition on all members of the \\u03b3-secretase family \\u2013 i.e. irrespective of the type of PSEN (1 vs 2) and APH1 (A vs B) subunits (Figure 1D). Quantitative western blotting analysis revealed a marked inhibition of total AICD production by all types of \\u03b3-secretases in the presence of 3 \\u03bcM human A\\u03b242. These findings support a competitive mechanism wherein low-affinity substrates (acting also as products) are able to re-associate with the protease and inhibit the processing of transmembrane substrates when present at relatively high concentrations. To gain further insights, we investigated \\u03b3-secretase mediated processing of A\\u03b242 to A\\u03b238 under the conditions used to examine APPC99, using the latter as a positive control (Figure 1E). Despite the use of relatively high concentrations of A\\u03b242 (10 \\u03bcM), this peptide was not converted into A\\u03b238. In contrast, proteolytic reactions using APPC99 (1.5 \\u03bcM) resulted in the generation of A\\u03b238 (0.5\\u20131 nM). We also tested whether A\\u03b242 served as a substrate in conditions that mimic a native-like environment, i.e. detergent resistant membranes (DRMs) (Figure 1E) (30, 45). As in the detergent conditions, A\\u03b242 was barely converted into A\\u03b238. We note that \\u03b3-secretase processes A\\u03b243 into A\\u03b240 under similar conditions, even when this peptide was added at much lower concentrations (0.5\\u20131 \\u03bcM) (30). Taken together, these observations indicate that exogenous A\\u03b242 does interact with \\u03b3-secretases but, unlike A\\u03b243, does not act as a substrate (at least under these conditions), supporting the notion that A\\u03b242-driven inhibition of \\u03b3-secretases is mediated via the formation of non-productive enzyme-substrate (E-S) like complexes. However, a scenario wherein A\\u03b242 interacts with APPC99 to reduce the amount of free APPC99 substrate available for the enzymatic cleavage is not excluded by these data. We also investigated whether the inhibitory effects of A\\u03b242 on \\u03b3-secretase were reversible. To this end, we conjugated purified \\u03b3-secretase complexes to beads using a high-affinity anti-NCSTN nanobody and incubated the enzyme-conjugated beads with 0.4 \\u03bcM APPC99, in the absence or presence of 3 \\u03bcM A\\u03b242, for 40 minutes at 37\\u00b0C. Note that this concentration of peptide substantially inhibited AICD generation (Figure 1B). As a control, 10 \\u03bcM \\u03b3-secretase inhibitor X (GSI, Inh X) was included. After the incubation, we collected the supernatants, washed the beads in assay buffer and re-incubated them with 0.4 \\u03bcM APPC99 for 40 minutes at 37\\u00b0C. Analysis of the levels of the de novo generated AICD products in the supernatant fractions collected before (reaction 1) and after washes (reaction 2) indicated that A\\u03b242 inhibition of \\u03b3-secretase is fully reversible (Figure 1F). Collectively, our analyses support a model wherein A\\u03b242 forms a non-productive E-S like complex with \\u03b3-secretase and its binding is reversible. We then investigated the structure-function relationships relevant to the A\\u03b242-driven inhibitory mechanism. The effects of mouse/rat (murine) A\\u03b242 and N-terminally truncated human A\\u03b2x-42 (11\\u201342 and 17\\u2013\",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Zoltowska2024a chunk 4\",\n",
      "            \"full_citation\": \"Zoltowska, Katarzyna Marta, et al. \\\"Alzheimer\\u2019s Disease Linked A\\u03b242 Exerts Product Feedback Inhibition on \\u03b3-Secretase Impairing Downstream Cell Signaling.\\\" *bioRxiv*, 2024, doi:10.1101/2023.08.02.551596. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 9\n",
      "    },\n",
      "    \"summary: The study investigates how familial Alzheimer's disease (FAD) mutations affect the proteolysis of the amyloid \\u03b2-protein precursor (APP) by \\u03b3-secretase. It reveals that these mutations alter the production ratio of A\\u03b242 (aggregation-prone, predominantly deposited in plaques) and A\\u03b240, ultimately leading to inefficient processing of longer A\\u03b2 forms (\\u226545 residues). Notably, the authors note that \\\"all 14 disease-causing mutations led to inefficient processing\\\" and indicate that specific FAD mutations affect the mechanism of proteolysis, wherein intermediate A\\u03b2 peptides bind and are not released, influencing the production of A\\u03b2 species relevant to Alzheimer\\u2019s pathology.\\n\\n8\": {\n",
      "        \"original_text\": \"Title: Familial Alzheimer\\u2019s disease mutations in amyloid protein precursor alter proteolysis by \\u03b3-secretase to increase amyloid \\u03b2-peptides of \\u226545 residues\\n\\nAuthors: Devkota Sujan, Williams Todd D., Wolfe Michael S.\\n\\nJournal: The Journal of Biological Chemistry\\nYear: 2021\\nPMC ID: 7948801\\nDOI: 10.1016/j.jbc.2021.100281\\nCitation Count: 26\\n\\nAbstract:\\nProduction of amyloid \\u03b2-protein (A\\u03b2) is carried out by the membrane-embedded \\u03b3-secretase complex. Mutations in the transmembrane domain of amyloid \\u03b2-protein precursor (APP) associated with early-onset familial Alzheimer's disease (FAD) can alter the ratio of aggregation-prone 42-residue A\\u03b2 (A\\u03b242) to 40-residue A\\u03b2 (A\\u03b240). However, APP substrate is proteolyzed processively by \\u03b3-secretase along two pathways: A\\u03b249\\u2192A\\u03b246\\u2192A\\u03b243\\u2192A\\u03b240 and A\\u03b248\\u2192A\\u03b245\\u2192A\\u03b242\\u2192A\\u03b238. Effects of FAD mutations on each proteolytic step are unknown, largely due to difficulties in detecting and quantifying longer A\\u03b2 peptides. To address this, we carried out systematic and quantitative analyses of all tri- and tetrapeptide coproducts from proteolysis of wild-type and 14 FAD-mutant APP substrates by purified \\u03b3-secretase. These small peptides, including FAD-mutant forms, were detected by tandem mass spectrometry and quantified by establishing concentration curves for each of 32 standards. APP intracellular domain (AICD) coproducts were quantified by immunoblot, and the ratio of AICD products corresponding to A\\u03b248 and A\\u03b249 was determined by mass spectrometry. Levels of individual A\\u03b2 peptides were determined by subtracting levels of peptide coproducts associated with degradation from those associated with production. This method was validated for A\\u03b240 and A\\u03b242 by specific ELISAs and production of equimolar levels of A\\u03b2 and AICD. Not all mutant substrates led to increased A\\u03b242/40. However, all 14 disease-causing mutations led to inefficient processing of longer forms of A\\u03b2 \\u2265 45 residues. In addition, the effects of certain mutations provided insight into the mechanism of processive proteolysis: intermediate A\\u03b2 peptides apparently remain bound for subsequent trimming and are not released and reassociated.\\n\\nFull Text:\\nCerebral plaques composed of the amyloid \\u03b2-protein (A\\u03b2) are a defining pathological feature of Alzheimer\\u2019s disease (1). A\\u03b2 is produced from the amyloid \\u03b2-protein precursor (APP) through sequential proteolysis, by \\u03b2-secretase shedding the ectodomain (2) followed by \\u03b3-secretase cutting within the transmembrane domain (TMD) of the remnant 99-residue C-terminal fragment (C99) (3). A\\u03b2 peptides of 38 to 43 residues are secreted, with the aggregation-prone 42-residue form (A\\u03b242) being predominantly and disproportionally deposited in AD plaques (4). A pathogenic role for A\\u03b242 was strongly supported by the discovery of dominant missense mutations in APP and presenilins\\u2014the catalytic component of the \\u03b3-secretase complex\\u2014that cause early-onset familial Alzheimer\\u2019s disease (FAD) (5). These mutations were found to elevate the ratio of A\\u03b242 to A\\u03b240, thereby increasing A\\u03b242 aggregation. Inconsistencies with the hypothesis that A\\u03b242 is the pathogenic variant in FAD emerged recently with a report on A\\u03b240 and A\\u03b242 production from 138 different FAD-mutant forms of the presenilin-1/\\u03b3-secretase complex, showing that many disease-causing mutations\",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Sujan2021 chunk 1\",\n",
      "            \"full_citation\": \"Sujan, Devkota, Todd D. Williams, and Michael S. Wolfe. \\\"Familial Alzheimer\\u2019s Disease Mutations in Amyloid Protein Precursor Alter Proteolysis by \\u03b3-Secretase to Increase Amyloid \\u03b2-Peptides of \\u226545 Residues.\\\" *The Journal of Biological Chemistry*, vol. 296, 2021, article 100281. DOI: 10.1016/j.jbc.2021.100281. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 8\n",
      "    },\n",
      "    \"summary: The excerpt establishes that human A\\u03b242 peptide at a concentration of 2.5 \\u03bcM significantly inhibits \\u03b3-secretase activity in biochemical assays. The study highlights that this inhibition is \\\"partial, reversible, and regulated by the relative concentrations\\\" of A\\u03b242 and its substrates. This mechanism suggests a connection between elevated A\\u03b242 levels, \\u03b3-secretase inhibition, and the accumulation of amyloid precursor protein (APP) C-terminal fragments (CTFs), which is relevant to Alzheimer's disease pathology. Additionally, it notes that A\\u03b242 can reach \\\"microM level in endosomes,\\\" contributing to its effects on \\u03b3-secretase.\\n\\n8\": {\n",
      "        \"original_text\": \"aptosome-enriched pellet was resuspended in HB supplemented with 10 mM glucose. 10\\u201315 \\u03bcg of synaptosome was incubated with A\\u03b242 peptide at 2.5 \\u03bcM final concentration at 37 \\u00b0C for 18 hr. DMSO was used as a vehicle control. One synaptosomal sample was treated with 200 nM of Compound E. Following incubation, samples were resolved on SDS-PAGE, and western blotting was performed using anti-APP Y188 and anti-GAPDH antibodies. All densitometric analyses were performed using NIH ImageJ software. The animal experiments were approved by the Institutional Animal Care and Use Committee of the University of California San Diego. Statistical analysis was performed using Excel, GraphPad Prism, R 4.2.2. and R Studio software. The following R packages were used for the analysis: readxl, ggplot2, plyr, dplyr, DescTools, gridExtra and reshape2 (Wickham, 2016; Wickham, 2007; Wickham, 2011). p<0.05 was considered as a predetermined threshold for statistical significance. One-way or two-way ANOVA, or Kruskal-Wallis test followed by Dunnett\\u2019s, Tukey\\u2019s, or Dunn multiple comparison test or unpaired Student\\u2019s t-test were used, as described in the legends. In this manuscript, the authors tested the hypothesis that A\\u03b242 toxicity arises from its proven affinity for \\u03b3-secretases. The authors provide useful findings, showing convincingly that human Abeta42 inhibits gamma-secretase activity. The data will be of interest to all scientists working on neurodegenerative diseases. Summary: Human Abeta42 inhibits gamma-secretase activity in biochemical assays. Strengths: Determination of inhibitory concentration human Abeta42 on gamma-secretase activity in biochemical assays. The following is the authors\\u2019 response to the original reviews. Reviewer #1 (Recommendations For The Authors): Major concerns: (1) It is not clear about the biological significance of the inhibitory effects of human Abeta42 on gammasecretase activity. As the authors mentioned in the Discussion, it is plausible that Abeta42 may concentrate up to microM level in endosomes. However, subsets of FAD mutations in APP and presenilin 1 and 2 increase Abeta42/Abeta40 ratio and lead to Abeta42 deposition in brain. APP knock-in mice NLF and NLGF also develop Abeta42 deposition in age-dependent manner, although they produce more human Abeta42 than human Abeta40. If the production of Abeta42 is attenuated, which results in less Abeta42 deposition in brain. So, it is unlikely that human Abeta42 interferes gamma-secretase activity in physiological conditions. This reviewer has an impression that inhibition of gamma-secretase by human Abeta42 is an interesting artifact in high Abeta42 concentration. If the authors disagree with this reviewer's comment, this manuscript needs more discussion in this point of view. We thank the Reviewer for raising this key conceptual point, we acknowledge that it was insufficiently discussed in the original manuscript. In response to this point, we introduced the following paragraph in the discussion section of the revised manuscript: \\u201cFrom a mechanistic standpoint, the competitive nature of the A\\u03b242-mediated inhibition implies that it is partial, reversible, and regulated by the relative concentrations of the A\\u03b242 peptide (inhibitor) and the endogenous substrates (Figure 10C and 10D). The model that we put forward is that cellular uptake, as well as endosomal production of A\\u03b2, result in increased intracellular concentration of A\\u03b242, facilitating \\u03b3-secretase inhibition and leading to the buildup of APP-CTFs (and \\u03b3-secretase substrates in general). As A\\u03b242 levels\",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Zoltowska2024 chunk 32\",\n",
      "            \"full_citation\": \"Zoltowska, Katarzyna Marta, et al. \\\"Alzheimer\\u2019s Disease Linked A\\u03b242 Exerts Product Feedback Inhibition on \\u03b3-Secretase Impairing Downstream Cell Signaling.\\\" *eLife*, vol. 13, 2024, doi:10.7554/eLife.90690. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 8\n",
      "    },\n",
      "    \"summary: The study establishes a link between A\\u03b242 and \\u03b3-secretase inhibition in the context of Alzheimer's disease (AD). It shows that human A\\u03b242 peptides inhibit \\u03b3-secretase activity, leading to the accumulation of unprocessed substrates in neurons, such as C-terminal fragments (CTFs) of amyloid precursor protein (APP) and p75. This inhibition disrupts downstream signaling pathways crucial for neuronal function and induces p75-dependent neuronal death. The findings indicate that \\\"pathological elevations in A\\u03b242 contribute to cellular toxicity via \\u03b3-secretase inhibition,\\\" highlighting potential implications for therapeutic interventions involving \\u03b3-secretase activity.\\n\\n8\": {\n",
      "        \"original_text\": \"Title: Alzheimer\\u2019s disease linked A\\u03b242 exerts product feedback inhibition on \\u03b3-secretase impairing downstream cell signaling\\n\\nAuthors: Zoltowska Katarzyna Marta, Das Utpal, Lismont Sam, Enzlein Thomas, Maesako Masato, Houser Mei CQ, Franco Maria Luisa, \\u00d6zcan Burcu, Gomes Moreira Diana, Karachentsev Dmitry, Becker Ann, Hopf Carsten, Vilar Mar\\u00e7al, Berezovska Oksana, Mobley William, Ch\\u00e1vez-Guti\\u00e9rrez Luc\\u00eda\\n\\nJournal: eLife\\nYear: 2024\\nPMC ID: 11259434\\nDOI: 10.7554/eLife.90690\\nCitation Count: 0\\n\\nAbstract:\\nAmyloid \\u03b2 (A\\u03b2) peptides accumulating in the brain are proposed to trigger Alzheimer\\u2019s disease (AD). However, molecular cascades underlying their toxicity are poorly defined. Here, we explored a novel hypothesis for A\\u03b242 toxicity that arises from its proven affinity for \\u03b3-secretases. We hypothesized that the reported increases in A\\u03b242, particularly in the endolysosomal compartment, promote the establishment of a product feedback inhibitory mechanism on \\u03b3-secretases, and thereby impair downstream signaling events. We conducted kinetic analyses of \\u03b3-secretase activity in cell-free systems in the presence of A\\u03b2, as well as cell-based and ex vivo assays in neuronal cell lines, neurons, and brain synaptosomes to assess the impact of A\\u03b2 on \\u03b3-secretases. We show that human A\\u03b242 peptides, but neither murine A\\u03b242 nor human A\\u03b217\\u201342 (p3), inhibit \\u03b3-secretases and trigger accumulation of unprocessed substrates in neurons, including C-terminal fragments (CTFs) of APP, p75, and pan-cadherin. Moreover, A\\u03b242 treatment dysregulated cellular homeostasis, as shown by the induction of p75-dependent neuronal death in two distinct cellular systems. Our findings raise the possibility that pathological elevations in A\\u03b242 contribute to cellular toxicity via the \\u03b3-secretase inhibition, and provide a novel conceptual framework to address A\\u03b2 toxicity in the context of \\u03b3-secretase-dependent homeostatic signaling.\\n\\nFull Text:\\n\\u0393-secretases are ubiquitously expressed intramembrane proteases best known for their pathogenic roles in Alzheimer's Disease (AD) (Ch\\u00e1vez-Guti\\u00e9rrez and Szaruga, 2020). Aberrant processing of the amyloid precursor protein (APP) by \\u03b3-secretases leads to the production of longer, aggregation-prone A\\u03b2 peptides that contribute to neurodegeneration (Selkoe and Hardy, 2016). In addition, \\u03b3-secretases process many other membrane proteins, including NOTCH, ERB-B2 receptor tyrosine kinase 4 (ERBB4), N-cadherin (NCAD), and p75 neurotrophin receptor (p75-NTR) (Haapasalo and Kovacs, 2011; G\\u00fcner and Lichtenthaler, 2020). The processing of multiple substrates links their activity to a broad range of downstream signaling pathways (Jurisch-Yaksi et al., 2013; Carroll and Li, 2016), including those critical for neuronal function. It is noteworthy that treatments with \\u03b3-secretase inhibitors caused cognitive worsening in AD patients (Doody et al., 2013), while full genetic inhibition of these enzymes in the adult mouse brain led to neurodegenerative phenotypes (Acx et al., 2017; Wines-Samuelson et al., 2010; Tabuchi et al., 2009; Saura et al., 2004; Bi et al\",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Zoltowska2024 chunk 1\",\n",
      "            \"full_citation\": \"Zoltowska, Katarzyna Marta, et al. \\\"Alzheimer\\u2019s Disease Linked A\\u03b242 Exerts Product Feedback Inhibition on \\u03b3-Secretase Impairing Downstream Cell Signaling.\\\" *eLife*, vol. 13, 2024, doi:10.7554/eLife.90690. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 8\n",
      "    },\n",
      "    \"summary: A\\u03b243 and A\\u03b242, neurotoxic peptides implicated in Alzheimer's disease (AD), are generated from the C99 fragment of the amyloid precursor protein (APP) by the \\u03b3-secretase complex, primarily composed of presenilin 1 (PS1). The study reveals that A\\u03b243 levels are significantly increased in several familial Alzheimer's disease (FAD) mutants due to altered C99 interactions, with the novel \\u03b3-secretase modulator RO7019009 effectively reducing A\\u03b243 production across all tested mutants. This suggests a potential therapeutic approach for patients with A\\u03b243-generating mutations through \\u03b3-secretase modulation. \\n\\n8\": {\n",
      "        \"original_text\": \"Title: A\\u03b243\\u2010producing PS1 FAD mutants cause altered substrate interactions and respond to \\u03b3\\u2010secretase modulation\\n\\nAuthors: Trambauer Johannes, Rodr\\u00edguez Sarmiento Rosa Mar\\u00eda, Fukumori Akio, Feederle Regina, Baumann Karlheinz, Steiner Harald\\n\\nJournal: EMBO Reports\\nYear: 2019\\nPMC ID: 6945062\\nDOI: 10.15252/embr.201947996\\nCitation Count: 14\\n\\nAbstract:\\nAbnormal generation of neurotoxic amyloid\\u2010\\u03b2 peptide (A\\u03b2) 42/43 species due to mutations in the catalytic presenilin 1 (PS1) subunit of \\u03b3\\u2010secretase is the major cause of familial Alzheimer's disease (FAD). Deeper mechanistic insight on the generation of A\\u03b243 is still lacking, and it is unclear whether \\u03b3\\u2010secretase modulators (GSMs) can reduce the levels of this A\\u03b2 species. By comparing several types of A\\u03b243\\u2010generating FAD mutants, we observe that very high levels of A\\u03b243 are often produced when presenilin function is severely impaired. Altered interactions of C99, the precursor of A\\u03b2, are found for all mutants and are independent of their particular effect on A\\u03b2 production. Furthermore, unlike previously described GSMs, the novel compound RO7019009 can effectively lower A\\u03b243 production of all mutants. Finally, substrate\\u2010binding competition experiments suggest that RO7019009 acts mechanistically after initial C99 binding. We conclude that altered C99 interactions are a common feature of diverse types of PS1 FAD mutants and that also patients with A\\u03b243\\u2010generating FAD mutations could in principle be treated by GSMs. Diverse types of FAD\\u2010associated PS1/\\u03b3\\u2010secretase mutants generating aberrant levels of neurotoxic A\\u03b243 alter positioning of the A\\u03b2 precursor substrate C99. Their pathogenic A\\u03b243 generation can be lowered by \\u03b3\\u2010secretase modulator RO7019009.\\n\\nFull Text:\\nAccumulation and deposition of amyloid\\u2010\\u03b2 peptide (A\\u03b2) species is a major pathological hallmark of Alzheimer's disease (AD) 1. The various A\\u03b2 species, 37\\u201343 amino acids in length, are generated from the C99 fragment of the amyloid precursor protein (APP) by presenilins 1 and 2 (PS1 and PS2), the catalytic subunits of the intramembrane\\u2010cleaving protease \\u03b3\\u2010secretase 2. Following an initial cleavage of the C99 transmembrane domain at the \\u03b5\\u2010site, which releases the APP intracellular domain (AICD) and gives rise to A\\u03b249 or A\\u03b248, further stepwise carboxy\\u2010terminal cleavages occur 2. A\\u03b249 is sequentially cleaved in a major product line to A\\u03b246, A\\u03b243, and A\\u03b240, the main A\\u03b2 species, as well as small amounts of A\\u03b237 (A\\u03b240 product line), while A\\u03b248 undergoes sequential cleavages in an alternative product line to A\\u03b245, A\\u03b242, and A\\u03b238 (A\\u03b242 product line) 3. The longer A\\u03b242 and A\\u03b243 species are highly aggregation\\u2010prone and neurotoxic and considered as the primary trigger of the disease 4. Since lowering of A\\u03b2 should be protective against AD pathogenesis, \\u03b3\\u2010secretase is a target for AD therapy. Small molecules targeting the enzyme that hold great potential to be beneficial in AD are \\u03b3\\u2010secretase modulators (GSMs) 5. GSMs alter the cleavage of C99 toward the production of non\\u2010toxic shorter A\\u03b2 species 6 and maintain the cleavage of physiologically important \\u03b3\\u2010secretase substrates 7, \",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Trambauer2019 chunk 1\",\n",
      "            \"full_citation\": \"Trambauer, Johannes, et al. \\\"A\\u03b243\\u2010Producing PS1 FAD Mutants Cause Altered Substrate Interactions and Respond to \\u03b3\\u2010Secretase Modulation.\\\" *EMBO Reports*, vol. 20, no. 5, 2019, doi:10.15252/embr.201947996. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 8\n",
      "    },\n",
      "    \"summary: The excerpt discusses how A\\u03b242 impacts \\u03b3-secretase activity in Alzheimer's disease (AD), highlighting that A\\u03b242 induces a \\\"competitive nature of inhibition,\\\" which is \\\"partial, reversible, and regulated by the relative concentrations\\\" of A\\u03b242 and its substrates. It explains that increased A\\u03b242 levels lead to altered \\u03b3-secretase signaling, affecting pathways like NOTCH, which is involved in memory formation. Additionally, intracellular concentrations of A\\u03b242 can reach up to ~10 nM in synaptosomes from end-stage AD brains, which is sufficient to inhibit \\u03b3-secretase in PC12 cells, implicating a cyclic mechanism in AD pathology.\\n\\n7\": {\n",
      "        \"original_text\": \" leading to changes in synaptic and axonal signaling (Xu et al., 2016; Kwart et al., 2019; Kim et al., 2016; Weissmiller et al., 2015; Sawa et al., 2022; Salehi et al., 2006; Jiang et al., 2019). Equally intriguing is the possibility that the general inhibition of \\u03b3-secretase substrates by A\\u03b242 could contribute to neuroinflammation by modifying microglia biology (Hou et al., 2023) and neurodegeneration, as reported previously for the genetic inactivation of these enzymes (Acx et al., 2017; Wines-Samuelson et al., 2010; Tabuchi et al., 2009; Saura et al., 2004). From a mechanistic standpoint, the competitive nature of the A\\u03b242-mediated inhibition implies that it is partial, reversible, and regulated by the relative concentrations of the A\\u03b242 peptide (inhibitor) and the endogenous substrates (Figure 10C and D). The model that we put forward is that cellular uptake, as well as endosomal production of A\\u03b2, result in increased intracellular concentration of A\\u03b242, facilitating \\u03b3-secretase inhibition and leading to the buildup of APP-CTFs (and \\u03b3-secretase substrates in general). As A\\u03b242 levels fall, the augmented concentration of substrates shifts the equilibrium towards their processing and subsequent A\\u03b2 production. As A\\u03b242 levels rise again, the equilibrium is shifted back towards the inhibition. This cyclic inhibitory mechanism will translate into pulses of (partial) \\u03b3-secretase inhibition, which will alter \\u03b3-secretase mediated-signaling (arising from increased CTF levels at the membrane or decreased release of soluble intracellular domains from substrates). These alterations may affect the dynamics of systems oscillating in the brain, such as NOTCH signaling, implicated in memory formation, and potentially others (related to e.g. cadherins, p75, or neuregulins). It is worth noting that oscillations in \\u03b3-secretase activity induced by treatment with a \\u03b3-secretase inhibitor semagacestat have been proposed to have contributed to the cognitive alterations observed in semagacestat-treated patients in the failed Phase-3 IDENTITY clinical trial (Doody et al., 2013) and that semagacestat, like A\\u03b242, acts as a high affinity competitor of substrates (Koch et al., 2023). The convergence of A\\u03b242 and tau at the synapse has been proposed to underlie synaptic dysfunction in AD (McInnes et al., 2018; Ittner et al., 2010; Roberson et al., 2007; Spires-Jones and Hyman, 2014), and recent assessment of APP-CTF levels in synaptosome-enriched fractions from healthy control, SAD, and FAD brains (temporal cortices) has shown that APP fragments concentrate at higher levels in the synapse in AD-affected than in control individuals (Ferrer-Ravent\\u00f3s, 2023). Our analysis adds that endogenous A\\u03b242 concentrates in synaptosomes derived from end-stage AD brains to reach ~10 nM, a concentration that in CM from human neurons inhibits \\u03b3-secretase in PC12 cells (Figure 7). Furthermore, the restricted localization of A\\u03b2 in endolysosomal vesicles, within synaptosomes, likely increases the local peptide concentration to the levels that inhibit \\u03b3-secretase-mediated processing of substrates in this compartment. In addition, we argue that the deposition of A\\u03b242 in plaques may be preceded by a critical increase in the levels of A\\u03b2 present in endosomes and the cyclical inhibition of \\u03b3-secretase activity that we propose. Under this view, reductions in\",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Zoltowska2024 chunk 23\",\n",
      "            \"full_citation\": \"Zoltowska, Katarzyna Marta, et al. \\\"Alzheimer\\u2019s Disease Linked A\\u03b242 Exerts Product Feedback Inhibition on \\u03b3-Secretase Impairing Downstream Cell Signaling.\\\" *eLife*, vol. 13, 2024, doi:10.7554/eLife.90690. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 7\n",
      "    },\n",
      "    \"summary: The study analyzes the impact of 138 pathogenic presenilin-1 (PS1) mutations on the in vitro production of \\u03b2-amyloid peptides (A\\u03b242 and A\\u03b240) by \\u03b3-secretase. Results show that approximately 90% of these mutations lead to a reduced production of both A\\u03b242 and A\\u03b240, while 10% decrease the A\\u03b242/A\\u03b240 ratio. This ratio is significant as increased levels of A\\u03b242, which correlates to amyloid plaque formation, are associated with Alzheimer's disease. Notably, there is \\\"no significant correlation\\\" between the A\\u03b242/A\\u03b240 ratio and the mean age at onset of patients with the mutations.\\n\\n8\": {\n",
      "        \"original_text\": \"Title: Analysis of 138 pathogenic mutations in presenilin-1 on the in vitro production of A\\u03b242 and A\\u03b240 peptides by \\u03b3-secretase\\n\\nAuthors: Sun Linfeng, Zhou Rui, Yang Guanghui, Shi Yigong\\n\\nJournal: Proceedings of the National Academy of Sciences of the United States of America\\nYear: 2017\\nPMC ID: 5278480\\nDOI: 10.1073/pnas.1618657114\\nCitation Count: 170\\n\\nAbstract:\\nAlzheimer\\u2019s disease (AD) is the most common form of dementia, but the cause of AD remains poorly understood. Using highly purified recombinant \\u03b3-secretase, we examined the effect of 138 AD-derived presenilin-1 (PS1) mutations on the production of \\u03b2-amyloid peptides (A\\u03b242 and A\\u03b240). These 138 mutations cover virtually all AD-targeted amino acids in PS1. Our results reveal no significant correlation between the A\\u03b242/A\\u03b240 ratio produced by a \\u03b3-secretase variant with a specific PS1 mutation and the mean age at onset of patients carrying this mutation. The comprehensive characterization of pathogenic PS1 mutations serves as a valuable resource for the analysis of \\u03b3-secretase activities and AD pathogenesis. A hallmark of Alzheimer\\u2019s disease (AD) is the aggregation of \\u03b2-amyloid peptides (A\\u03b2) into amyloid plaques in patient brain. Cleavage of amyloid precursor protein (APP) by the intramembrane protease \\u03b3-secretase produces A\\u03b2 of varying lengths, of which longer peptides such as A\\u03b242 are thought to be more harmful. Increased ratios of longer A\\u03b2s over shorter ones, exemplified by the ratio of A\\u03b242 over A\\u03b240, may lead to formation of amyloid plaques and consequent development of AD. In this study, we analyzed 138 reported mutations in human presenilin-1 (PS1) by individually reconstituting the mutant PS1 proteins into anterior-pharynx\\u2013defective protein 1 (APH-1)aL\\u2013containing \\u03b3-secretases and examining their abilities to produce A\\u03b242 and A\\u03b240 in vitro. About 90% of these mutations lead to reduced production of A\\u03b242 and A\\u03b240. Notably, 10% of these mutations result in decreased A\\u03b242/A\\u03b240 ratios. There is no statistically significant correlation between the A\\u03b242/A\\u03b240 ratio produced by a \\u03b3-secretase variant containing a specific PS1 mutation and the mean age at onset of patients from whom the mutation was isolated.\\n\\nFull Text:\\n\\n\",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Linfeng2017 chunk 1\",\n",
      "            \"full_citation\": \"Linfeng, Sun, Rui Zhou, Guanghui Yang, and Yigong Shi. \\\"Analysis of 138 Pathogenic Mutations in Presenilin-1 on the In Vitro Production of A\\u03b242 and A\\u03b240 Peptides by \\u03b3-Secretase.\\\" *Proceedings of the National Academy of Sciences of the United States of America*, vol. 114, no. 11, 2017, pp. E2387-E2396. doi:10.1073/pnas.1618657114. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 4\n",
      "    },\n",
      "    \"summary: \\u03b3-Secretase, a multimeric protease complex comprising presenilin (PSEN1/PSEN2), nicastrin (NCSTN), APH1A/B, and PEN2, plays a crucial role in the amyloidogenic processing of amyloid precursor protein (APP), producing amyloid \\u03b2 (A\\u03b2) peptides, specifically A\\u03b237-42. The initial \\u03b3-secretase endopeptidase (\\u03b5-) cut releases the APP intracellular domain (AICD) and generates substrates leading to A\\u03b2 formation. \\\"The efficiency of the sequential cleavage mechanism... determines the length of A\\u03b2,\\\" where mutations favoring amyloidogenic processing are linked to Alzheimer's disease, while those favoring non-amyloidogenic pathways confer protection against it.\\n\\n7\": {\n",
      "        \"original_text\": \"degenerative phenotypes (Acx et al., 2017; Wines-Samuelson et al., 2010; Tabuchi et al., 2009; Saura et al., 2004; Bi et al., 2021). The underlying mechanisms by which the deficits in \\u03b3-secretase activity impair neuronal function are yet to be defined. \\u0393-secretase activity is exerted by a family of highly homologous multimeric proteases composed of presenilin (PSEN1 or PSEN2), nicastrin (NCSTN), anterior pharynx defective 1 (APH1A or B), and presenilin enhancer 2 (PEN2) subunits. The proteolytic activities of these complexes are promoted by the low pH of the endosomal and lysosomal compartments, wherein the amyloidogenic processing of APP occurs (Maesako et al., 2022). In the amyloidogenic pathway, the proteolytic processing of APP by \\u03b2-secretase (BACE) releases a soluble APP ectodomain and generates a membrane-bound C-terminal fragment (\\u03b2-CTF or APPC99) (Vassar et al., 1999). APPC99 is then sequentially processed within the membrane by \\u03b3-secretase complexes (Figure 1A; Takami et al., 2009; Bolduc et al., 2016; Ch\\u00e1vez-Guti\\u00e9rrez et al., 2012; Qi-Takahara et al., 2005; Funamoto et al., 2004). An initial endopeptidase (\\u03b5-) cut releases the APP intracellular domain (AICD) into the cytosol and generates a de novo substrate (either A\\u03b249 or A\\u03b248 peptide) that undergoes successive \\u03b3-cleavages until a shortened A\\u03b2 peptide can be released into the luminal or extracellular environment. The efficiency of the sequential cleavage mechanism (i.e. processivity) determines the length of A\\u03b2 (37\\u201343 amino acid long peptides), which in turn influences the aggregation and neurotoxic properties of the peptides produced (Selkoe and Hardy, 2016; Kakuda et al., 2017; Fu et al., 2017). In the non-amyloidogenic pathway APP is cleaved by \\u03b1- and \\u03b3-secretases to generate a spectrum of p3 peptides, which lack the first 1\\u201316 amino acids of A\\u03b2 (Figure 1A). Despite their relatively high hydrophobicity and aggregation-prone behavior, the p3 peptides are not linked to AD pathogenesis (Kuhn and Raskatov, 2020; Lichtenthaler, 2011; Tambini et al., 2020). In fact, mutations that promote the amyloidogenic processing of APP are associated with AD (Mullan et al., 1992; Pagnon de la Vega et al., 2021), whereas those that favor the alternative, non-amyloidogenic pathway protect against the disease (Tambini et al., 2020; Jansen et al., 2019). (A) The scheme depicts the \\u03b3-secretase-mediated cleavage of amyloid precursor protein (APP), leading to the generation of amyloid \\u03b2 (A\\u03b2) and p3 peptides. The N-terminal sequence of APPC99 /A\\u03b2 is shown in the lower panel. The differences in the amino acid sequence of human (hu) vs murine (mu) A\\u03b2 peptides and the positions of \\u03b2\\u2019- and \\u03b1-cleavages (that precede the generation of A\\u03b211\\u201342 and p3 17\\u201342 peptides, respectively) are indicated. The transmembrane domain is labeled in grey and the sequence of A\\u03b242 is presented within a rectangle. The initial \\u03b3-secretase endopept\",\n",
      "        \"source\": {\n",
      "            \"chunk_id\": \"Zoltowska2024 chunk 2\",\n",
      "            \"full_citation\": \"Zoltowska, Katarzyna Marta, et al. \\\"Alzheimer\\u2019s Disease Linked A\\u03b242 Exerts Product Feedback Inhibition on \\u03b3-Secretase Impairing Downstream Cell Signaling.\\\" *eLife*, vol. 13, 2024, doi:10.7554/eLife.90690. Accessed 2024.\"\n",
      "        },\n",
      "        \"relevance_score\": 1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer = \"\"\" ### Working Hypothesis\n",
    "\n",
    "The working hypothesis for targeting gamma secretase (GSEC) in Alzheimer's disease (AD) is based on the premise that the dysregulation of amyloid-beta (Aβ) peptide production, particularly the accumulation of neurotoxic forms such as Aβ42 and Aβ43, is a central pathogenic mechanism in AD. Inhibition of GSEC could reduce the production of these longer, aggregation-prone Aβ peptides, thereby potentially preventing or slowing the formation of amyloid plaques, which are hallmarks of AD pathology.\n",
    "\n",
    "### Unmet Medical Need\n",
    "\n",
    "AD represents a significant unmet medical need, with millions of individuals affected globally and no disease-modifying treatments available. Current therapies primarily address symptomatic relief but do not halt or reverse the underlying disease process. The need for effective interventions that target the amyloid cascade hypothesis, particularly through modulation of GSEC activity, is critical to altering the disease trajectory.\n",
    "\n",
    "### Suitability for Combination Therapy\n",
    "\n",
    "Targeting GSEC may be suitable for combination therapy with other approaches aimed at reducing Aβ aggregation or enhancing clearance mechanisms, such as monoclonal antibodies targeting Aβ or therapies enhancing microglial function. Combination strategies could provide a multifaceted approach to addressing the complex pathophysiology of AD.\n",
    "\n",
    "### Predictive Biomarkers\n",
    "\n",
    "Existing clinical biomarkers related to GSEC and Aβ metabolism include:\n",
    "\n",
    "- **Amyloid PET Imaging**: This imaging technique allows for the visualization of amyloid plaques in the brain, providing evidence of the pathological burden of Aβ in living patients.\n",
    "  \n",
    "- **CSF Aβ Levels**: Measurement of Aβ42 and Aβ40 in cerebrospinal fluid (CSF) is clinically relevant, as a decrease in Aβ42 relative to Aβ40 is indicative of amyloid pathology.\n",
    "\n",
    "- **Neurodegeneration Biomarkers**: Markers such as phosphorylated tau (p-tau) in CSF and neurofilament light chain (NfL) can provide insights into neurodegeneration processes linked to GSEC activity and Aβ accumulation.\n",
    "\n",
    "### Clinical Target Rationale\n",
    "\n",
    "#### Relevance of Target Location to Disease Biology\n",
    "\n",
    "GSEC is located in the membrane of neurons and glial cells, where it plays a crucial role in the cleavage of APP. This positioning is highly relevant to AD biology, as Aβ peptides generated by GSEC are central to the formation of amyloid plaques, a key pathological feature of AD.\n",
    "\n",
    "#### Altered Target Expression in Human Disease\n",
    "\n",
    "Studies have shown that GSEC activity may be dysregulated in AD, leading to increased production of toxic Aβ species. Additionally, post-mortem analyses of AD brains have indicated altered expression levels of GSEC subunits, which may contribute to the pathological processing of APP.\n",
    "\n",
    "#### Involvement in Physiological Processes\n",
    "\n",
    "GSEC is involved in the physiological processing of APP and other type I transmembrane proteins. Its cleavage activity not only generates Aβ but also produces signaling molecules such as the APP intracellular domain (AICD), which may have neuroprotective roles. The balance of these processes is crucial for maintaining neuronal health.\n",
    "\n",
    "#### Identified Phenotypes and Genotypes\n",
    "\n",
    "Genetic studies have identified several mutations in the APP, PSEN1, and PSEN2 genes, which encode components of the GSEC complex. These mutations are associated with familial forms of AD, underscoring the genetic link between GSEC activity and AD pathogenesis.\n",
    "\n",
    "#### Evidence from Clinical Studies\n",
    "\n",
    "Clinical evidence supporting the role of GSEC in AD includes the efficacy of GSEC inhibitors in preclinical models and the observation that modulation of Aβ levels correlates with cognitive outcomes. Furthermore, ongoing clinical trials targeting GSEC provide additional insights into the potential therapeutic benefit of this approach.\n",
    "\n",
    "#### Required Target Modulation\n",
    "\n",
    "To effectively treat AD, modulation of GSEC should ideally aim to reduce the production of neurotoxic Aβ peptides while preserving the cleavage of other substrates necessary for neuronal function. A fine balance must be struck to achieve therapeutic efficacy without compromising physiological processes.\n",
    "\n",
    "### Challenges for Drug Discovery Program\n",
    "\n",
    "Challenges in developing GSEC inhibitors include the complexity of the GSEC multi-subunit structure, potential off-target effects due to the involvement of GSEC in the processing of various substrates, and the need for specificity to avoid disrupting normal physiological functions.\n",
    "\n",
    "### Information Driven Approach (IDA)\n",
    "\n",
    "An information-driven approach for developing small molecule inhibitors of GSEC is feasible, leveraging existing knowledge of the GSEC complex and its role in Aβ production.\n",
    "\n",
    "#### Known Small Molecular Modulators\n",
    "\n",
    "Several small molecular modulators of GSEC have been identified, including:\n",
    "\n",
    "- **GSEC Inhibitors**: Compounds that selectively inhibit GSEC activity have shown promise in preclinical studies, demonstrating reduced Aβ production.\n",
    "\n",
    "- **Positive Allosteric Modulators (PAMs)**: These may enhance the cleavage of non-amyloidogenic substrates while inhibiting Aβ production.\n",
    "\n",
    "#### Required Modulators for Target Modulation\n",
    "\n",
    "Inhibitors and antagonists are necessary for reducing Aβ production, while PAMs may be explored to fine-tune GSEC activity. Negative allosteric modulators (NAMs) could also be beneficial in modulating GSEC activity in a more controlled manner.\n",
    "\n",
    "### Patient Response to Therapy\n",
    "\n",
    "Patients with AD who exhibit elevated levels of Aβ42 and Aβ43 or those with genetic predispositions linked to GSEC dysregulation may be more likely to respond to GSEC-targeted therapies.\n",
    "\n",
    "### Desirability and Commercial Viability\n",
    "\n",
    "The proposed mode of action targeting GSEC is desirable, as it addresses a core pathological mechanism in AD. Commercial viability is supported by the large patient population and the significant unmet need for disease-modifying therapies.\n",
    "\n",
    "### Advantages and Disadvantages of Therapeutic Modalities\n",
    "\n",
    "- **Antibodies**: High specificity and potential for targeting aggregated forms of Aβ, but may not penetrate the blood-brain barrier effectively.\n",
    "\n",
    "- **Small Molecules**: Potential for oral bioavailability and better CNS penetration, but may face challenges with selectivity and off-target effects.\n",
    "\n",
    "- **Antisense Oligonucleotides**: Target specific mRNA for Aβ production, but delivery to the CNS remains a challenge.\n",
    "\n",
    "- **PROTACs**: Offer a novel mechanism for targeted protein degradation, but complexity in design and delivery may hinder development.\n",
    "\n",
    "- **Molecular Glue and Peptide Macrocycles**: Emerging modalities with potential for selective targeting, though still in early stages of research.\n",
    "\n",
    "### Alternative Indications\n",
    "\n",
    "Potential alternative indications for GSEC modulators could include other neurodegenerative diseases characterized by protein aggregation, such as frontotemporal dementia or Parkinson's disease. The rationale for these indications lies in the shared pathological mechanisms involving protein misfolding and aggregation, suggesting that GSEC modulation may have broader therapeutic implications beyond AD.########################################\n",
    "Processing draft...\"\"\"\n",
    "\n",
    "\n",
    "results = await main(chatgpt_prompt, answer, num_queries=5)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 3\n",
    "num_steps = 3\n",
    "final_output_mode = 'only_last_step'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def COT_agent(question):\n",
    "    \"\"\"Generates a chain of thought answer for comparison to RATT.\n",
    "    question: str: the prompt to answer\n",
    "    draft_prompt: str: the prompt to generate the draft\n",
    "    system_prompt: str: the prompt to generate the system message\"\"\"\n",
    "\n",
    "    draft_prompt = '''\n",
    "IMPORTANT:\n",
    "Try to answer this question/instruction with step-by-step thoughts and make the answer more structured.\n",
    "Use `\\n\\n` to split the answer into several paragraphs.\n",
    "Just respond to the instruction directly. DO NOT add additional explanations or introducement in the answer unless you are asked to.\n",
    "'''\n",
    "\n",
    "    # Loop to generate different initial answers\n",
    "    COT_draft = openai.chat.completions.create(\n",
    "         model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": scientific_rationale_system_prompt # defined at the top\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": question + draft_prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.5\n",
    "        ).choices[0].message.content\n",
    "\n",
    "    return COT_draft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def split_draft(draft, split_char='\\n\\n'):\n",
    "    # split_char: '\\n\\n'\n",
    "    draft_paragraphs = draft.split(split_char)\n",
    "    # print(f\"The draft answer has {len(draft_paragraphs)}\")\n",
    "    return draft_paragraphs\n",
    "\n",
    "\n",
    "def get_revise_answer(question, answer, retrieved_data):\n",
    "    revise_prompt = '''\n",
    "I want to revise the answer according to retrieved related text of the question in WIKI pages.\n",
    "You need to check whether the answer is correct.\n",
    "If you find some errors in the answer, revise the answer to make it better.\n",
    "If you find some necessary details are ignored, add it to make the answer more plausible according to the related text.\n",
    "If you find that a part of the answer is correct and does not require any additional details, maintain that part of the answer unchanged. Directly output the original content of that part without any modifications.\n",
    "**IMPORTANT**\n",
    "Try to keep the structure (multiple paragraphs with its subtitles) in the revised answer and make it more structual for understanding.\n",
    "Split the paragraphs with `\\n\\n` characters.\n",
    "Just output the revised answer directly. DO NOT add additional explanations or annoucement in the revised answer unless you are asked to.\n",
    "'''\n",
    "    revised_answer = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"##Pubmed central retrieved articles: {retrieved_data}\\n\\n##Question: {question}\\n\\n##previous Answer: {answer}\\n\\n##Instruction: {revise_prompt}\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    \n",
    "    return revised_answer\n",
    "\n",
    "\n",
    "\n",
    "async def RAG(question, draft_paragraphs):\n",
    "    \"\"\" args:\n",
    "    question: str: the prompt to answer\n",
    "    draft_paragraphs: list: the list of paragraphs from the initial n drafts\n",
    "    \"\"\"\n",
    "    answer = \"\"\n",
    "\n",
    "    for i, paragraph in enumerate(draft_paragraphs):\n",
    "        answer += '\\n\\n' + paragraph\n",
    "\n",
    "        api_response = await main(question, answer, num_queries=2)  # Now using the entire answer instead of just the paragraph\n",
    "\n",
    "        revised_answer = get_revise_answer(question, answer, api_response)  # Using the entire answer\n",
    "        if revised_answer:\n",
    "            answer = revised_answer  # Update the entire answer\n",
    "        \n",
    "        print(f\"Completed iteration {i+1}/{len(draft_paragraphs)}\")\n",
    "\n",
    "        print('+'* 80 + '\\n\\n')\n",
    "        print(f\"RESULT OF PUBMED API:\\n{answer}\")\n",
    "    \n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "def split_draft(draft, split_char='\\n\\n'):\n",
    "    # split_char: '\\n\\n'\n",
    "    draft_paragraphs = draft.split(split_char)\n",
    "    # print(f\"The draft answer has {len(draft_paragraphs)}\")\n",
    "    return draft_paragraphs\n",
    "\n",
    "\n",
    "\n",
    "def get_draft_tot_initial(question: str, num_agents: int):\n",
    "    \"\"\"Generates initial answers from multiple agents for comparison\"\"\"\n",
    "    draft_prompt = \"\"\"\n",
    "            IMPORTANT:\n",
    "            Try to answer this question/instruction with step-by-step thoughts and make the answer more structured.\n",
    "            Use `\\n\\n` to split the answer into several paragraphs.\n",
    "            Just respond to the instruction directly. DO NOT add additional explanations or introducement in the answer unless you are asked to.\n",
    "            \"\"\"\n",
    "\n",
    "    refine_prompt = \"\"\"\n",
    "            Referencing the answers provided by all agents, synthesize a more detailed and comprehensive response by integrating all relevant details from these answers. \n",
    "            Ensure logical coherence and provide ONLY THE MERGED ANSWER AS THE OUTPUT, omitting any discussion of the comparison process or analytical thoughts.\"\"\"\n",
    "\n",
    "    agent_drafts = []\n",
    "    for i in range(num_agents):\n",
    "        draft = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": question + draft_prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.5\n",
    "        ).choices[0].message.content\n",
    "        print(f\"####################draft {i}: {draft}########################################\")\n",
    "\n",
    "        print(\"Processing draft...\")\n",
    "        draft_paragraphs = split_draft(draft)\n",
    "\n",
    "        draft_modified = RAG(question, draft_paragraphs)\n",
    "\n",
    "        agent_drafts.append(f\"Agent{i+1}: {draft_modified}\")\n",
    "\n",
    "        print(f\"[INFO] Agent{i + 1}/{num_agents} retrieved draft...\")\n",
    "\n",
    "        agent_input = '\\n\\n'.join(agent_drafts) + '\\n\\n' + refine_prompt\n",
    "\n",
    "        final_draft = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": agent_input\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.5\n",
    "        ).choices[0].message.content\n",
    "\n",
    "        print(f\"{datetime.now()} - Final draft: {final_draft}\")\n",
    "\n",
    "\n",
    "    return final_draft\n",
    "\n",
    "# FIX BELOW FUNCTION NOT USING PREVIOUS ANSWER ?? ALSO STRING CHAR LIST WITHIN LIST - SHOULD BE STRING\n",
    "\n",
    "\n",
    "def get_draft_tot(question, previous_answer, num_agents):\n",
    "\n",
    "    draft_prompt = \"\"\" Base your response on the provided question and the previous answer. Expand the answer by adding more details to enhance its comprehensiveness. Ensure that the expansion maintains logical coherence and enriches the details, making the response more thorough and well-structured.\n",
    "        Question: {question}\n",
    "        Previous Answer: {previous_answer}\n",
    "        IMPORTANT:\n",
    "        Answer the full question with step-by-step thoughts and make the answer more structural.\n",
    "        Use `\\n\\n` to split the answer into several paragraphs.\n",
    "        Just respond to the instruction directly. DO NOT add additional explanations or introducement in the answer unless you are asked to. \"\"\"\n",
    "\n",
    "    refine_prompt = \"\"\" \n",
    "        Referencing the answers provided by all agents, synthesize a more detailed and comprehensive response by integrating all relevant details from these answers. Ensure logical coherence and provide ONLY THE MERGED ANSWER AS THE OUTPUT, omitting any discussion of the comparison process or analytical thoughts.\n",
    "\"\"\"\n",
    "\n",
    "    agents_drafts = []\n",
    "    for i in range(num_agents):\n",
    "        draft = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": draft_prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.5\n",
    "        ).choices[0].message.content\n",
    "\n",
    "        draft_paragraphs = split_draft(draft)\n",
    "\n",
    "        draft_modified = RAG(question, draft_paragraphs)\n",
    "\n",
    "        agents_drafts.append(f\"Agent{i+1}: {draft_modified}\")\n",
    "    \n",
    "    agents_input = '\\n\\n'.join(agents_drafts) + '\\n\\n' + refine_prompt\n",
    "\n",
    "    final_draft_raw = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": agents_input\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    print(f\"##########Final draft raw #########################: {final_draft_raw}...\")\n",
    "\n",
    "    revise_prompt = \"\"\"\n",
    "            Based on the original answer and an additional supplementary answer, generate a response that is richer in detail and logically coherent. Review the original answer:\n",
    "        1. If any part of the answer is correct and requires no further details, retain that portion unchanged and output it directly as it is.\n",
    "        2. For parts that may be improved or lack necessary details, enhance them by integrating information from the supplementary answer to make the response more comprehensive and accurate.\n",
    "        3. If you identify any errors within the answers, correct these errors while ensuring that the revised content remains logically coherent.\n",
    "        Original Answer: {previous_answer}\n",
    "        Supplementary Answer: {final_draft_raw}\n",
    "\n",
    "        **IMPORTANT**\n",
    "        Ensure the revised answer maintains a structured format (multiple paragraphs with subtitles) for better clarity. \n",
    "        Separate the paragraphs with `\\n\\n` characters. Output only the enhanced answer directly, without any extra explanations or a\n",
    "        nnouncements unless specifically requested.\"\"\"\n",
    "    \n",
    "    final_draft = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": revise_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    return final_draft\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def ratt(question, num_agents):\n",
    "    step_num = num_steps\n",
    "    print(f\"{datetime.now()} [INFO] Retrieving Step 1 draft...\")\n",
    "    draft = get_draft_tot_initial(question,num_agents)\n",
    "    print(f\"{datetime.now()} [INFO] Step 1 draft returned\")\n",
    "    print(f\"##################### DRAFT #######################\")\n",
    "    print(draft)\n",
    "    print(f\"#####################  END  #######################\")\n",
    "\n",
    "    print(f\"{datetime.now()} [INFO] Processing draft...\")\n",
    "    draft_paragraphs = split_draft(draft)\n",
    "    print(f\"{datetime.now()} [INFO] Draft split into {len(draft_paragraphs)} parts\")\n",
    "\n",
    "    answer_first_state = RAG(question, draft_paragraphs)\n",
    "\n",
    "    previous_answer = answer_first_state\n",
    "\n",
    "    each_step_drafts = [f\"Step 1 \\n: {previous_answer}\"]\n",
    "\n",
    "    for iteration in range(1, step_num):\n",
    "        print(f\"{datetime.now()} [INFO] Retrieving Step {iteration + 1} draft...\")\n",
    "        draft = get_draft_tot(question, previous_answer, num_agents=num_agents)\n",
    "        print(f\"{datetime.now()} [INFO] Step {iteration + 1} draft returned\")\n",
    "        print(f\"##################### DRAFT #######################\")\n",
    "        print(draft)\n",
    "        print(f\"#####################  END  #######################\")\n",
    "\n",
    "        print(f\"{datetime.now()} [INFO] Processing draft...\")\n",
    "        draft_paragraphs = split_draft(draft)\n",
    "        print(f\"{datetime.now()} [INFO] Draft split into {len(draft_paragraphs)} parts\")\n",
    "\n",
    "        # filtered_paragraphs = filter_paragraphs(draft_paragraphs, iteration, step_num)\n",
    "        final_answer = RAG(question, draft_paragraphs)\n",
    "\n",
    "        each_step_drafts.append(f\"Step {iteration + 1} \\n: {final_answer}\")\n",
    "\n",
    "        # Update previous_answer for the current iteration's response\n",
    "        previous_answer = final_answer\n",
    "\n",
    "    draft_cot = COT_agent(question) # for comparison\n",
    "\n",
    "    if final_output_mode == 'combine_each_step':\n",
    "        final_draft = '\\n\\n'.join(each_step_drafts)\n",
    "        refine_prompt = f\"\"\"\n",
    "                        Referencing the answers provided by each step, synthesize a more detailed and comprehensive response by integrating all relevant details from these answers. Ensure logical coherence and provide ONLY THE MERGED ANSWER AS THE OUTPUT, omitting any discussion of the comparison process or analytical thoughts.\n",
    "                        \"\"\"\n",
    "        previous_answer = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": final_draft + '\\n\\n' + refine_prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=1.0\n",
    "        ).choices[0].message.content\n",
    "\n",
    "    return draft_cot, previous_answer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:41:18.229172 [INFO] Retrieving Step 1 draft...\n",
      "####################draft 0: # Scientific Rationale for Gamma Secretase in Alzheimer's Disease\n",
      "\n",
      "## Working Hypothesis\n",
      "\n",
      "Gamma secretase (GSEC) is a multi-subunit protease complex that cleaves type I transmembrane proteins, including the amyloid precursor protein (APP), leading to the generation of amyloid-beta (Aβ) peptides. The accumulation of Aβ peptides, particularly Aβ42, in the brain is a hallmark of Alzheimer's disease (AD) and is believed to play a crucial role in the pathogenesis of the disease. The working hypothesis is that modulation of GSEC activity could reduce the production of pathogenic Aβ42, thereby mitigating amyloid plaque formation and slowing the progression of AD.\n",
      "\n",
      "## Unmet Medical Need\n",
      "\n",
      "Alzheimer's disease is a progressive neurodegenerative disorder with no cure and limited treatment options. Current therapies primarily offer symptomatic relief and do not address the underlying pathophysiology of the disease. There is a significant unmet medical need for disease-modifying therapies that can slow or halt the progression of AD by targeting the production of pathogenic Aβ peptides.\n",
      "\n",
      "## Suitability for Combination Therapy\n",
      "\n",
      "Gamma secretase inhibitors could potentially be used in combination with other therapeutic agents targeting different aspects of AD pathology, such as tau protein aggregation, inflammation, and synaptic dysfunction. Combination therapy could provide a more comprehensive approach to managing the disease by addressing multiple pathological mechanisms simultaneously.\n",
      "\n",
      "## Predictive Biomarkers\n",
      "\n",
      "### Existing Clinical Relevant Biomarkers\n",
      "\n",
      "- **Aβ42/Aβ40 Ratio:** The ratio of Aβ42 to Aβ40 in cerebrospinal fluid (CSF) is a well-established biomarker for AD. A decrease in this ratio is indicative of AD pathology.\n",
      "- **Amyloid PET Imaging:** Positron emission tomography (PET) imaging using amyloid-specific tracers can visualize amyloid plaque deposition in the brain.\n",
      "- **CSF Tau Levels:** Elevated levels of total tau and phosphorylated tau in CSF are associated with AD and correlate with disease severity.\n",
      "- **Genetic Markers:** Mutations in genes such as APP, PSEN1, and PSEN2 are linked to familial AD and can serve as genetic biomarkers for the disease.\n",
      "\n",
      "## Clinical Target Rationale\n",
      "\n",
      "### Relevance to Disease Biology\n",
      "\n",
      "Gamma secretase is directly involved in the production of Aβ peptides, which aggregate to form amyloid plaques—a key pathological feature of AD. By modulating GSEC activity, it is possible to influence the production of Aβ42, thereby impacting plaque formation and disease progression.\n",
      "\n",
      "### Altered Target Expression in Human Disease\n",
      "\n",
      "Mutations in the presenilin subunits of GSEC (PSEN1 and PSEN2) are associated with early-onset familial AD. These mutations alter GSEC activity, leading to an increased production of Aβ42. Additionally, increased GSEC activity has been observed in sporadic AD cases, suggesting its role in disease pathology.\n",
      "\n",
      "### Involvement in Physiological Processes\n",
      "\n",
      "GSEC is involved in the cleavage of several type I transmembrane proteins, including APP. The cleavage of APP by GSEC is a critical step in the production of Aβ peptides. Dysregulation of this process leads to the accumulation of Aβ42, which seeds the formation of amyloid plaques.\n",
      "\n",
      "### Phenotypes and Genotypes\n",
      "\n",
      "- **Phenotypes:** Patients with familial AD due to PSEN1 or PSEN2 mutations exhibit early-onset cognitive decline and increased amyloid plaque deposition.\n",
      "- **Genotypes:** Mutations in APP, PSEN1, and PSEN2 genes are strongly linked to familial AD. These mutations result in altered GSEC activity and increased production of Aβ42.\n",
      "\n",
      "### Genetic Link to Disease\n",
      "\n",
      "The genetic link between GSEC and AD is well-established through mutations in APP, PSEN1, and PSEN2 genes. These mutations lead to altered GSEC activity and increased Aβ42 production, directly contributing to AD pathology.\n",
      "\n",
      "### Clinical Evidence\n",
      "\n",
      "Clinical trials with GSEC inhibitors have shown mixed results, with some compounds reducing Aβ levels but also causing adverse effects due to the broad substrate specificity of GSEC. This highlights the need for selective modulation of GSEC activity to achieve the desired clinical outcome without off-target effects.\n",
      "\n",
      "### Required Target Modulation\n",
      "\n",
      "To treat AD, selective inhibition of GSEC activity to reduce the production of Aβ42 while preserving the cleavage of other essential substrates is required. This selective modulation could potentially mitigate amyloid plaque formation and slow disease progression.\n",
      "\n",
      "## Challenges for Drug Discovery\n",
      "\n",
      "### Information-Driven Approach\n",
      "\n",
      "An information-driven approach (IDA) based on available small molecules is possible, leveraging existing knowledge of GSEC structure and function to design selective inhibitors.\n",
      "\n",
      "### Known Small Molecular Modulators\n",
      "\n",
      "- **Inhibitors:** Several GSEC inhibitors have been developed, but their lack of selectivity has led to adverse effects.\n",
      "- **Antagonists and Agonists:** Specific antagonists or agonists targeting GSEC subunits could provide a more selective approach.\n",
      "- **Negative Allosteric Modulators (NAM):** NAMs could selectively inhibit GSEC activity on APP without affecting other substrates.\n",
      "- **Positive Allosteric Modulators (PAM):** PAMs are not applicable in this context as GSEC inhibition is desired.\n",
      "\n",
      "### Patient Response\n",
      "\n",
      "Patients with early-stage AD or those with genetic mutations in APP, PSEN1, or PSEN2 may respond better to GSEC inhibitors. Biomarkers such as Aβ42/Aβ40 ratio and amyloid PET imaging can help identify suitable candidates.\n",
      "\n",
      "### Desirability and Commercial Viability\n",
      "\n",
      "The proposed mode of action—selective inhibition of GSEC to reduce Aβ42 production—is desirable and commercially viable if off-target effects can be minimized. Successful development could lead to a disease-modifying therapy for AD.\n",
      "\n",
      "### Therapeutic Modalities\n",
      "\n",
      "- **Antibodies:** Targeting GSEC with antibodies could provide high specificity but may face challenges in brain penetration.\n",
      "- **Small Molecules:** Small molecule inhibitors offer better brain penetration but require high selectivity to avoid off-target effects.\n",
      "- **Antisense Oligonucleotides:** These could selectively reduce expression of specific GSEC subunits but may have delivery challenges.\n",
      "- **PROTACs:** Proteolysis-targeting chimeras (PROTACs) could selectively degrade GSEC subunits, offering a novel approach.\n",
      "- **Peptide Macrocycles:** These could provide high selectivity but may have stability and delivery challenges.\n",
      "\n",
      "## Alternative Indications\n",
      "\n",
      "### Potential Alternative Indications\n",
      "\n",
      "- **Cancer:** GSEC is involved in the Notch signaling pathway, which plays a role in certain cancers. Modulators of GSEC could be explored for cancer therapy.\n",
      "- **Other Neurodegenerative Diseases:** GSEC is involved in the cleavage of other substrates implicated in neurodegeneration, such as Notch and N-cadherin. Modulation of GSEC could have therapeutic potential in other neurodegenerative diseases.\n",
      "\n",
      "### Rationale for Alternative Indications\n",
      "\n",
      "The involvement of GSEC in multiple signaling pathways and its broad substrate specificity suggest that GSEC modulators could have therapeutic potential beyond AD. Exploring alternative indications could provide additional therapeutic opportunities and expand the clinical utility of GSEC inhibitors.########################################\n",
      "Processing draft...\n",
      "[INFO] Agent1/1 retrieved draft...\n",
      "2024-08-01 16:42:03.954906 - Final draft: I'm sorry, but it seems like you've referenced a coroutine object without providing any specific information or context for me to synthesize. Could you please provide the answers or details from the agents that you would like me to merge into a comprehensive response?\n",
      "2024-08-01 16:42:03.956650 [INFO] Step 1 draft returned\n",
      "##################### DRAFT #######################\n",
      "I'm sorry, but it seems like you've referenced a coroutine object without providing any specific information or context for me to synthesize. Could you please provide the answers or details from the agents that you would like me to merge into a comprehensive response?\n",
      "#####################  END  #######################\n",
      "2024-08-01 16:42:03.956779 [INFO] Processing draft...\n",
      "2024-08-01 16:42:03.956800 [INFO] Draft split into 1 parts\n",
      "2024-08-01 16:42:03.956869 [INFO] Retrieving Step 2 draft...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/3877540748.py:7: RuntimeWarning: coroutine 'RAG' was never awaited\n",
      "  draft = get_draft_tot_initial(question,num_agents)\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/324958690.py\", lineno 110\n",
      "    draft_modified = RAG(question, draft_paragraphs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Final draft raw #########################: I'm sorry, but I don't have access to the specific answers provided by the agents. If you can share the details or content of their responses, I would be happy to help synthesize a comprehensive answer based on that information....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/3877540748.py:25: RuntimeWarning: coroutine 'RAG' was never awaited\n",
      "  draft = get_draft_tot(question, previous_answer, num_agents=num_agents)\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/324958690.py\", lineno 173\n",
      "    draft_modified = RAG(question, draft_paragraphs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:42:07.009256 [INFO] Step 2 draft returned\n",
      "##################### DRAFT #######################\n",
      "I'm sorry, but I cannot fulfill that request without the original answer and the supplementary answer provided. Please share the content you would like me to enhance, and I'll be happy to assist you.\n",
      "#####################  END  #######################\n",
      "2024-08-01 16:42:07.009549 [INFO] Processing draft...\n",
      "2024-08-01 16:42:07.009609 [INFO] Draft split into 1 parts\n",
      "2024-08-01 16:42:07.009673 [INFO] Retrieving Step 3 draft...\n",
      "##########Final draft raw #########################: I'm sorry, but it seems that I cannot access or retrieve the specific responses from the agents you mentioned. If you provide me with the answers or details from those agents, I can help synthesize a comprehensive response based on that information....\n",
      "2024-08-01 16:42:09.415372 [INFO] Step 3 draft returned\n",
      "##################### DRAFT #######################\n",
      "I'm sorry, but I cannot assist with that.\n",
      "#####################  END  #######################\n",
      "2024-08-01 16:42:09.415698 [INFO] Processing draft...\n",
      "2024-08-01 16:42:09.415758 [INFO] Draft split into 1 parts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/3877540748.py:41: RuntimeWarning: coroutine 'RAG' was never awaited\n",
      "  previous_answer = final_answer\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/3877540748.py\", lineno 36\n",
      "    final_answer = RAG(question, draft_paragraphs)\n",
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/967180656.py:1: RuntimeWarning: coroutine 'RAG' was never awaited\n",
      "  answer_cot, answer_ratt = ratt(chatgpt_prompt, num_agents=1)\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/3877540748.py\", lineno 17\n",
      "    answer_first_state = RAG(question, draft_paragraphs)\n"
     ]
    }
   ],
   "source": [
    "answer_cot, answer_ratt = ratt(chatgpt_prompt, num_agents=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_draft test passed\n",
      "Revised answer: The capital of France is Paris. \n",
      "\n",
      "\n",
      "get_revise_answer test passed\n",
      "Completed iteration 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/1479425663.py:50: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  api_response = main(question, answer, num_queries=2)  # Now using the entire answer instead of just the paragraph\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/1479425663.py\", lineno 50\n",
      "    api_response = main(question, answer, num_queries=2)  # Now using the entire answer instead of just the paragraph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration 2/2\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "RESULT OF PUBMED API:\n",
      "The primary colors are red, blue, and yellow.\n",
      "\n",
      "In color theory, primary colors are defined as colors that cannot be created by mixing other colors together. They serve as the foundation for creating a wide range of other colors through various combinations.\n",
      "\n",
      "In the additive color model, which is used in contexts like television and computer screens, the primary colors are red, green, and blue (RGB). By mixing these colors in different ways, a broad spectrum of colors can be produced.\n",
      "\n",
      "In contrast, the subtractive color model, commonly used in painting and printing, identifies red, blue, and yellow as the primary colors. When mixed together, these colors can create a variety of other hues.\n",
      "\n",
      "It's important to note that in the subtractive color model, yellow is indeed considered a primary color, while in the additive model, the primary colors are red, green, and blue.\n",
      "RAG result: The primary colors are red, blue, and yellow.\n",
      "\n",
      "In color theory, primary colors are defined as colors that cannot be created by mixing other colors together. They serve as the foundation for creating a wide range of other colors through various combinations.\n",
      "\n",
      "In the additive color model, which is used in contexts like television and computer screens, the primary colors are red, green, and blue (RGB). By mixing these colors in different ways, a broad spectrum of colors can be produced.\n",
      "\n",
      "In contrast, the subtractive color model, commonly used in painting and printing, identifies red, blue, and yellow as the primary colors. When mixed together, these colors can create a variety of other hues.\n",
      "\n",
      "It's important to note that in the subtractive color model, yellow is indeed considered a primary color, while in the additive model, the primary colors are red, green, and blue.\n",
      "RAG test passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/3750429350.py:30: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  result = RAG(question, draft_paragraphs)\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/var/folders/02/fvfmdq_j709g1tthj47t5fcm0000gn/T/ipykernel_17808/1479425663.py\", lineno 50\n",
      "    api_response = main(question, answer, num_queries=2)  # Now using the entire answer instead of just the paragraph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################draft 0: The water cycle, also known as the hydrological cycle, is a continuous process that describes the movement of water within the Earth's atmosphere, land, and bodies of water. The cycle can be broken down into several key stages:\n",
      "\n",
      "1. **Evaporation**: The process begins when the sun heats up water in rivers, lakes, and oceans. This heat causes the water to evaporate, turning it into water vapor that rises into the atmosphere. Plants also contribute to this process through transpiration, where water is absorbed by roots and released as vapor from leaves.\n",
      "\n",
      "2. **Condensation**: As water vapor rises, it cools and condenses into tiny droplets, forming clouds. This process occurs when the air temperature drops and the water vapor reaches its dew point, leading to the formation of clouds in the atmosphere.\n",
      "\n",
      "3. **Precipitation**: Eventually, the water droplets in clouds combine to form larger droplets. When they become heavy enough, they fall back to the Earth's surface as precipitation in the form of rain, snow, sleet, or hail, depending on the temperature conditions.\n",
      "\n",
      "4. **Collection**: The precipitation collects in bodies of water such as rivers, lakes, and oceans. Some of it also infiltrates the ground, replenishing groundwater supplies. This collected water will eventually return to the atmosphere through evaporation, continuing the cycle.\n",
      "\n",
      "5. **Runoff**: Water that does not infiltrate the ground flows over the surface as runoff, eventually making its way back to oceans and lakes. This process helps to transport nutrients and sediments, supporting ecosystems along the way.\n",
      "\n",
      "Through these stages, the water cycle plays a crucial role in maintaining the Earth's climate and supporting life by distributing water across various environments.########################################\n",
      "Processing draft...\n",
      "Completed iteration 1/7\n",
      "Completed iteration 2/7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2 drafts, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_draft_tot_initial test passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mtest_get_draft_tot_initial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[145], line 41\u001b[0m, in \u001b[0;36mtest_get_draft_tot_initial\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain the water cycle.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m num_agents \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 41\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mget_draft_tot_initial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_agents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of drafts: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, draft \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(result):\n",
      "Cell \u001b[0;32mIn[144], line 104\u001b[0m, in \u001b[0;36mget_draft_tot_initial\u001b[0;34m(question, num_agents)\u001b[0m\n\u001b[1;32m    100\u001b[0m drafts\u001b[38;5;241m.\u001b[39mappend(draft_paragraphs)\n\u001b[1;32m    102\u001b[0m draft_paragraphs \u001b[38;5;241m=\u001b[39m split_draft(draft)\n\u001b[0;32m--> 104\u001b[0m draft_modified \u001b[38;5;241m=\u001b[39m \u001b[43mRAG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraft_paragraphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m drafts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdraft_modified\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Agent\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_agents\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m retrieved draft...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[144], line 52\u001b[0m, in \u001b[0;36mRAG\u001b[0;34m(question, draft_paragraphs)\u001b[0m\n\u001b[1;32m     48\u001b[0m answer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m paragraph\n\u001b[1;32m     50\u001b[0m api_response \u001b[38;5;241m=\u001b[39m main(question, answer, num_queries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Now using the entire answer instead of just the paragraph\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m revised_answer \u001b[38;5;241m=\u001b[39m \u001b[43mget_revise_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_response\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Using the entire answer\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m revised_answer:\n\u001b[1;32m     54\u001b[0m     answer \u001b[38;5;241m=\u001b[39m revised_answer  \u001b[38;5;66;03m# Update the entire answer\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[144], line 20\u001b[0m, in \u001b[0;36mget_revise_answer\u001b[0;34m(question, answer, retrieved_data)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_revise_answer\u001b[39m(question, answer, retrieved_data):\n\u001b[1;32m      9\u001b[0m     revise_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124mI want to revise the answer according to retrieved related text of the question in WIKI pages.\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mYou need to check whether the answer is correct.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mJust output the revised answer directly. DO NOT add additional explanations or annoucement in the revised answer unless you are asked to.\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m---> 20\u001b[0m     revised_answer \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m##Pubmed central retrieved articles: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mretrieved_data\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m##Question: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquestion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m##previous Answer: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43manswer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m##Instruction: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrevise_prompt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m revised_answer\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/openai/resources/chat/completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/openai/_base_client.py:1261\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1249\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1257\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1258\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1259\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1260\u001b[0m     )\n\u001b[0;32m-> 1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/openai/_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/openai/_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    970\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 973\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM_agent/lib/python3.12/ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First, make sure you have all the necessary imports and have defined all the functions from your original code\n",
    "\n",
    "# Then, create test cells for each function:\n",
    "\n",
    "# Test split_draft\n",
    "def test_split_draft():\n",
    "    test_draft = \"Paragraph 1\\n\\nParagraph 2\\n\\nParagraph 3\"\n",
    "    result = split_draft(test_draft)\n",
    "    assert len(result) == 3, f\"Expected 3 paragraphs, got {len(result)}\"\n",
    "    print(\"split_draft test passed\")\n",
    "\n",
    "test_split_draft()\n",
    "\n",
    "# Test get_revise_answer\n",
    "def test_get_revise_answer():\n",
    "    question = \"What is the capital of France?\"\n",
    "    answer = \"The capital of France is London.\"\n",
    "    retrieved_data = \"The capital of France is Paris.\"\n",
    "    result = get_revise_answer(question, answer, retrieved_data)\n",
    "    print(f\"Revised answer: {result}\")\n",
    "    assert \"Paris\" in result, f\"Expected 'Paris' in the revised answer\"\n",
    "    print(\"get_revise_answer test passed\")\n",
    "\n",
    "test_get_revise_answer()\n",
    "\n",
    "# Test RAG\n",
    "def test_RAG():\n",
    "    question = \"What are the primary colors?\"\n",
    "    draft_paragraphs = [\"The primary colors are red and blue.\", \"Yellow is also a primary color.\"]\n",
    "    result = RAG(question, draft_paragraphs)\n",
    "    print(f\"RAG result: {result}\")\n",
    "    assert \"red\" in result.lower() and \"blue\" in result.lower() and \"yellow\" in result.lower(), f\"Expected all primary colors in the result\"\n",
    "    print(\"RAG test passed\")\n",
    "\n",
    "test_RAG()\n",
    "\n",
    "# Test get_draft_tot_initial\n",
    "def test_get_draft_tot_initial():\n",
    "    question = \"Explain the water cycle.\"\n",
    "    num_agents = 2\n",
    "    result = get_draft_tot_initial(question, num_agents)\n",
    "    print(f\"Number of drafts: {len(result)}\")\n",
    "    for i, draft in enumerate(result):\n",
    "        print(f\"Draft {i+1}:\\n{draft}\\n\")\n",
    "    assert len(result) == 2, f\"Expected 2 drafts, got {len(result)}\"\n",
    "    print(\"get_draft_tot_initial test passed\")\n",
    "\n",
    "test_get_draft_tot_initial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
